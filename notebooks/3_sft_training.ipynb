{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT with QLoRA - OPTIMIZED FOR KAGGLE\n\n**Goals:** 75-80% cost reduction, 60-70% time reduction\n\n**Optimizations:**\n- QLoRA (4-bit quantization) for 3-4x speedup\n- 30% dataset sampling for faster training\n- BF16 precision (stable, no gradient scaling issues)\n- 2 epochs instead of 3\n- Estimated time: 3-5 hours \u2705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install with bitsandbytes for QLoRA support\n!pip install -q transformers datasets peft trl accelerate wandb evaluate bitsandbytes scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')\n",
    "import torch, time, json, os\n",
    "from src.data.loader import DatasetLoader\n",
    "from src.data.processor import DataProcessor\n",
    "from src.model.base import load_base_model, load_base_model_qlora, load_tokenizer, get_model_info\n",
    "from src.model.lora import LoRAWrapper\n",
    "from src.training.sft import SFTTrainer\n",
    "from src.utils.metrics import MetricsTracker\n",
    "\n",
    "# Optional wandb - no API key required\n",
    "try:\n",
    "    import wandb\n",
    "    wandb.init(project='persona-chatbot-rlhf', name='sft-qlora', mode='disabled')  # offline mode\n",
    "    USE_WANDB = True\n",
    "except:\n",
    "    USE_WANDB = False\n",
    "    class wandb:\n",
    "        @staticmethod\n",
    "        def log(*args, **kwargs): pass\n",
    "        @staticmethod\n",
    "        def finish(): pass\n",
    "\n",
    "print(f'W&B: {\"enabled (offline)\" if USE_WANDB else \"disabled\"}')\n",
    "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config - OPTIMIZED FOR KAGGLE (3-5 hour runtime)\nmodel_config = {\n    'name': 'gpt2-medium',\n    'cache_dir': '../models/base',\n    'device_map': 'auto',\n    'use_qlora': True  # Enable QLoRA for 3-4x speedup\n}\n\n# LoRA config - Optimized for speed (r=8 instead of 16)\nlora_config = {\n    'r': 8,                    # Reduced from 16 (faster, still effective)\n    'alpha': 16,               # Reduced from 32 (matched to r)\n    'dropout': 0.05,           # Reduced from 0.1\n    'target_modules': ['c_attn'],  # Only attention (faster than c_attn + c_proj)\n    'bias': 'none',\n    'task_type': 'CAUSAL_LM'\n}\n\n# Training config - Optimized for Kaggle 9-12h limit\ntraining_config = {\n    'output_dir': '../models/sft',\n    'num_epochs': 2,                 # 3 \u2192 2 (1.5x faster)\n    'max_steps': 3000,               # Hard limit for safety\n    'per_device_batch_size': 8,      # 4 \u2192 8 (QLoRA saves memory)\n    'gradient_accumulation_steps': 4,  # Effective batch = 32\n    'learning_rate': 2e-4,\n    'warmup_steps': 300,             # 500 \u2192 300 (fewer steps needed)\n    'weight_decay': 0.01,\n    'bf16': True,                    # CRITICAL: Use BF16 not FP16 (prevents precision errors)\n    'gradient_checkpointing': True,  # Memory efficient\n    'logging_steps': 50,\n    'eval_steps': 300,               # Must be divisor of save_steps               # 500 \u2192 300 (more frequent)\n    'save_steps': 600,               # Must be multiple of eval_steps (for load_best_model_at_end)               # 1000 \u2192 500\n    'save_total_limit': 2,           # Keep only 2 checkpoints\n    'dataloader_num_workers': 2,     # Parallel data loading\n    'optim': 'paged_adamw_8bit',     # 8-bit optimizer for QLoRA\n    'use_wandb': False\n}\n\ndata_config = {\n    'base_model': 'gpt2-medium',\n    'max_length': 512,\n    'dataset_fraction': 0.3  # Use 30% for faster training (can increase to 0.5 if needed)\n}\n\nprint('Configuration loaded:')\nprint(f'  - QLoRA: {model_config[\"use_qlora\"]}')\nprint(f'  - Dataset: {data_config[\"dataset_fraction\"]*100}%')\nprint(f'  - Precision: BF16 (safe, no gradient scaling)')\nprint(f'  - Max steps: {training_config[\"max_steps\"]}')\nprint(f'  - Estimated time: 3-5 hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - OPTIMIZED: Use 30% subset\n",
    "print('Loading dataset...')\n",
    "loader = DatasetLoader()\n",
    "train_full = loader.load_personachat(split='train', use_synthetic=True)\n",
    "val_full = loader.load_personachat(split='validation', use_synthetic=True)\n",
    "\n",
    "# Sample dataset for faster training\n",
    "dataset_fraction = data_config.get('dataset_fraction', 0.3)\n",
    "train_size = int(len(train_full) * dataset_fraction)\n",
    "val_size = int(len(val_full) * dataset_fraction)\n",
    "\n",
    "print(f'\\nSampling {dataset_fraction*100}% of dataset:')\n",
    "print(f'  Train: {len(train_full)} \u2192 {train_size} examples')\n",
    "print(f'  Val: {len(val_full)} \u2192 {val_size} examples')\n",
    "\n",
    "train = train_full.select(range(train_size))\n",
    "val = val_full.select(range(val_size))\n",
    "\n",
    "# Preprocess and tokenize\n",
    "print('\\nPreprocessing...')\n",
    "processor = DataProcessor(config=data_config)\n",
    "train_proc = processor.tokenize(processor.preprocess(train))\n",
    "val_proc = processor.tokenize(processor.preprocess(val))\n",
    "print(f'Processed: {len(train_proc)} train, {len(val_proc)} val examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model + QLoRA - OPTIMIZED VERSION\n",
    "print('\\nLoading model...')\n",
    "\n",
    "# Load with QLoRA if enabled (3-4x faster than regular LoRA)\n",
    "if model_config.get('use_qlora', False):\n",
    "    print('Using QLoRA (4-bit quantization):')\n",
    "    model = load_base_model_qlora(model_config)\n",
    "else:\n",
    "    print('Using regular LoRA (slower):')\n",
    "    model = load_base_model(model_config)\n",
    "\n",
    "tokenizer = load_tokenizer(model_config)\n",
    "total_p = get_model_info(model)['total_parameters']\n",
    "\n",
    "# Apply LoRA\n",
    "print('\\nApplying LoRA adapters...')\n",
    "lora = LoRAWrapper(lora_config)\n",
    "model = lora.apply_lora(model, lora_config)\n",
    "lora.print_trainable_params(model)\n",
    "\n",
    "trainable_p = get_model_info(model)['trainable_parameters']\n",
    "reduction = (1 - trainable_p/total_p) * 100\n",
    "\n",
    "print(f'\\nModel statistics:')\n",
    "print(f'  Total params: {total_p/1e6:.0f}M')\n",
    "print(f'  Trainable params: {trainable_p/1e6:.1f}M')\n",
    "print(f'  Reduction: {reduction:.1f}%')\n",
    "if model_config.get('use_qlora', False):\n",
    "    print(f'  Memory savings (QLoRA): ~75%')\n",
    "    print(f'  Speed improvement: 3-4x faster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with optimized settings\n",
    "print('\\nStarting training...')\n",
    "print(f'  Epochs: {training_config[\"num_epochs\"]}')\n",
    "print(f'  Batch size: {training_config[\"per_device_batch_size\"]}')\n",
    "print(f'  Gradient accumulation: {training_config[\"gradient_accumulation_steps\"]}')\n",
    "print(f'  Effective batch: {training_config[\"per_device_batch_size\"] * training_config[\"gradient_accumulation_steps\"]}')\n",
    "print(f'  Max steps: {training_config[\"max_steps\"]}')\n",
    "print(f'  Precision: BF16 (safe, no gradient scaling issues)')\n",
    "print(f'\\nEstimated steps: ~{(len(train_proc) // (training_config[\"per_device_batch_size\"] * training_config[\"gradient_accumulation_steps\"])) * training_config[\"num_epochs\"]}')\n",
    "print(f'Estimated time: 3-5 hours\\n')\n",
    "\n",
    "tracker = MetricsTracker(gpu_hourly_rate=0.35)\n",
    "tracker.start_timing()\n",
    "os.makedirs(training_config['output_dir'], exist_ok=True)\n",
    "\n",
    "trainer = SFTTrainer(model, tokenizer, train_proc, val_proc, training_config)\n",
    "results = trainer.train()\n",
    "\n",
    "print('\\n\u2705 Training complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and validation\n",
    "hours = tracker.stop_timing() / 3600\n",
    "gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
    "cost = tracker.track_cost(hours, gpus)\n",
    "savings = tracker.calculate_savings('full_finetuning', 'lora')\n",
    "\n",
    "print(f'\\nTraining Results:')\n",
    "print(f'  Time: {hours:.2f} hours')\n",
    "print(f'  Cost: ${cost:.2f}')\n",
    "print(f'\\nSavings vs Full Fine-tuning:')\n",
    "print(f'  Time: {savings[\"time_savings_percent\"]:.1f}% (target: 60-70%)')\n",
    "print(f'  Cost: {savings[\"cost_savings_percent\"]:.1f}% (target: 75-80%)')\n",
    "\n",
    "cost_ok = savings['cost_savings_percent'] >= 75\n",
    "time_ok = savings['time_savings_percent'] >= 60\n",
    "\n",
    "print(f'\\nTargets Met:')\n",
    "print(f'  Cost: {\"\u2705\" if cost_ok else \"\u274c\"}  {savings[\"cost_savings_percent\"]:.1f}% >= 75%')\n",
    "print(f'  Time: {\"\u2705\" if time_ok else \"\u274c\"}  {savings[\"time_savings_percent\"]:.1f}% >= 60%')\n",
    "\n",
    "wandb.log({\n",
    "    'hours': hours,\n",
    "    'cost': cost,\n",
    "    'time_savings%': savings['time_savings_percent'],\n",
    "    'cost_savings%': savings['cost_savings_percent'],\n",
    "    'qlora_enabled': model_config.get('use_qlora', False)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and summary\n",
    "print('\\nSaving model...')\n",
    "path = f\"{training_config['output_dir']}/final\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)\n",
    "\n",
    "summary = {\n",
    "    'params': int(trainable_p),\n",
    "    'hours': hours,\n",
    "    'cost': cost,\n",
    "    'savings_time%': savings['time_savings_percent'],\n",
    "    'savings_cost%': savings['cost_savings_percent'],\n",
    "    'targets_met': {'cost': cost_ok, 'time': time_ok},\n",
    "    'config': {\n",
    "        'qlora_enabled': model_config.get('use_qlora', False),\n",
    "        'dataset_fraction': data_config.get('dataset_fraction', 1.0),\n",
    "        'precision': 'BF16' if training_config.get('bf16') else 'FP32'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{training_config['output_dir']}/summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(f'\\n\u2705 Model saved to {path}')\n",
    "print(f'\u2705 Summary saved to {training_config[\"output_dir\"]}/summary.json')\n",
    "print(f'\\n\ud83c\udf89 SFT training complete! Next: 4_reward_and_ppo.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}